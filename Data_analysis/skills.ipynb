{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Finance_cleaned_file.csv')\n",
    "df['info'].to_csv('finance_skills.csv', index=False)\n",
    "df=pd.read_csv('Internet_cleaned_file.csv')\n",
    "df['info'].to_csv('internet_skills.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             count\n",
      "skill             \n",
      "java          6003\n",
      "c             5695\n",
      "python        3884\n",
      "后端开发          3565\n",
      "电路设计          3125\n",
      "cad           2820\n",
      "springboot    2819\n",
      "店铺运营          2800\n",
      "电气设计          2583\n",
      "mysql         2509\n",
      "web前端         2443\n",
      "c语言           2405\n",
      "视觉设计          2379\n",
      "ps            2355\n",
      "springcloud   2326\n",
      "售后客服          2305\n",
      "pcb设计         2295\n",
      "电话客服          2265\n",
      "vue           2250\n",
      "sql           2244\n",
      "无销售性质         2152\n",
      "售前客服          2080\n",
      "全职            2062\n",
      "短视频运营         1994\n",
      "销售运营          1964\n",
      "推广运营          1899\n",
      "linux         1825\n",
      "javascript    1795\n",
      "嵌入式硬件开发       1779\n",
      "公众号           1716\n",
      "运营专员          1695\n",
      "品类运营          1684\n",
      "普通话标准流利       1681\n",
      "朋友圈运营         1642\n",
      "solidworks    1627\n",
      "数据分析          1594\n",
      "需求分析          1561\n",
      "react         1478\n",
      "社群运营          1474\n",
      "oracle        1463\n",
      "产品规划          1450\n",
      "ai            1424\n",
      "商家运营          1388\n",
      "to            1386\n",
      "结构设计          1382\n",
      "嵌入式软件开发       1363\n",
      "产品运营          1327\n",
      "css           1285\n",
      "plc           1272\n",
      "产品设计          1271\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('internet_skills.csv')\n",
    "\n",
    "# Define a dictionary to store the cleaned skills\n",
    "skills_dict = {}\n",
    "\n",
    "# Iterate through each row in the info column\n",
    "for row in df['info']:\n",
    "    # Extract the skills from the row and clean them\n",
    "    row_skills = re.findall(r'\\b\\w+\\b', row.lower())\n",
    "    row_skills = {s.strip() for s in row_skills if s.strip() and s not in ['TO C', 'TO B', 'TO G', '早九晚六', '五险一金', '应届生', '银行', '线下授课']}\n",
    "    \n",
    "    # Count the frequency of each skill and update the skills dictionary\n",
    "    for skill in row_skills:\n",
    "        skill_lower = skill.lower() # convert skill to lowercase\n",
    "        if skill_lower in skills_dict:\n",
    "            skills_dict[skill_lower] += 1\n",
    "        else:\n",
    "            skills_dict[skill_lower] = 1\n",
    "\n",
    "# Filter out low-frequency skills\n",
    "skills_dict = {k: v for k, v in skills_dict.items() if v >= 1000}\n",
    "\n",
    "# Count the frequency of each skill in the dataframe\n",
    "skills_count = {k: sum(df['info'].str.lower().str.contains(r'\\b{}\\b'.format(re.escape(k)))) for k in skills_dict.keys()}\n",
    "\n",
    "# Convert the skills count dictionary to a pandas dataframe and sort by count\n",
    "skills_count_df = pd.DataFrame.from_dict(skills_count, orient='index', columns=['count'])\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df = skills_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Count the frequency of each skill in the dataframe and save to a csv file\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df.to_csv('skills_counts.csv')\n",
    "\n",
    "# Only show the top 50 skills with the highest count\n",
    "skills_count_top50 = skills_count_df.head(50)\n",
    "print(skills_count_top50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('internet_skills.csv')\n",
    "\n",
    "# Define a dictionary to store the cleaned skills\n",
    "skills_dict = {}\n",
    "\n",
    "# Iterate through each row in the info column\n",
    "for row in df['info']:\n",
    "    # Extract the skills from the row and clean them\n",
    "    row_skills = re.findall(r'\\b\\w+\\b', row.lower())\n",
    "    row_skills = {s.strip() for s in row_skills if s.strip() and s not in ['TO C', 'TO B', 'TO G', '早九晚六', '五险一金', '应届生', '银行', '线下授课']}\n",
    "    \n",
    "    # Count the frequency of each skill and update the skills dictionary\n",
    "    for skill in row_skills:\n",
    "        skill_lower = skill.lower() # convert skill to lowercase\n",
    "        if skill_lower in skills_dict:\n",
    "            skills_dict[skill_lower] += 1\n",
    "        else:\n",
    "            skills_dict[skill_lower] = 1\n",
    "\n",
    "# Filter out low-frequency skills\n",
    "skills_dict = {k: v for k, v in skills_dict.items() if v >= 10}\n",
    "\n",
    "# Count the frequency of each skill in the dataframe\n",
    "skills_count = {k: sum(df['info'].str.lower().str.contains(r'\\b{}\\b'.format(re.escape(k)))) for k in skills_dict.keys()}\n",
    "\n",
    "# Convert the skills count dictionary to a pandas dataframe and sort by count\n",
    "skills_count_df = pd.DataFrame.from_dict(skills_count, orient='index', columns=['count'])\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df = skills_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Count the frequency of each skill in the dataframe and save to a csv file\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df.to_csv('skills_counts_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('finance_skills.csv')\n",
    "\n",
    "# Define a dictionary to store the cleaned skills\n",
    "skills_dict = {}\n",
    "\n",
    "# Iterate through each row in the info column\n",
    "for row in df['info']:\n",
    "    # Extract the skills from the row and clean them\n",
    "    row_skills = re.findall(r'\\b\\w+\\b', row.lower())\n",
    "    row_skills = {s.strip() for s in row_skills if s.strip() and s not in ['TO C', 'TO B', 'TO G', '早九晚六', '五险一金', '应届生', '银行', '线下授课','旅游业', '农/林/牧/渔', '餐饮业','全国', '不出差','汽车','互联网行业','典当业','C端客户','建筑业','个人业务', '全职']}\n",
    "    \n",
    "    # Count the frequency of each skill and update the skills dictionary\n",
    "    for skill in row_skills:\n",
    "        skill_lower = skill.lower() # convert skill to lowercase\n",
    "        if skill_lower in skills_dict:\n",
    "            skills_dict[skill_lower] += 1\n",
    "        else:\n",
    "            skills_dict[skill_lower] = 1\n",
    "\n",
    "# Filter out low-frequency skills\n",
    "skills_dict = {k: v for k, v in skills_dict.items() if v >= 500}\n",
    "\n",
    "# Count the frequency of each skill in the dataframe\n",
    "skills_count = {k: sum(df['info'].str.lower().str.contains(r'\\b{}\\b'.format(re.escape(k)))) for k in skills_dict.keys()}\n",
    "\n",
    "# Convert the skills count dictionary to a pandas dataframe and sort by count\n",
    "skills_count_df = pd.DataFrame.from_dict(skills_count, orient='index', columns=['count'])\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df = skills_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Count the frequency of each skill in the dataframe and save to a csv file\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df.to_csv('finance_skills_counts_all.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count\n",
      "skill         \n",
      "面销        7155\n",
      "销售专员      6445\n",
      "电话销售      6366\n",
      "网络销售      5217\n",
      "个人客户      4685\n",
      "金融销售      4431\n",
      "保险销售      3919\n",
      "渠道销售      3733\n",
      "企业客户      3587\n",
      "2c        3566\n",
      "房地产       2961\n",
      "保险行业      2871\n",
      "销售经理      2826\n",
      "2b        2803\n",
      "大客户       2790\n",
      "ka        2779\n",
      "互联网金融     2572\n",
      "证券从业资格证   2549\n",
      "贷款行业      2394\n",
      "投资        2348\n",
      "理财        2328\n",
      "大客户销售     2226\n",
      "电销        2224\n",
      "基金从业资格证   2162\n",
      "销售主管      2104\n",
      "二手房销售     2082\n",
      "理财销售      2051\n",
      "金融        1986\n",
      "证券        1963\n",
      "店面销售      1915\n",
      "房屋租赁      1698\n",
      "新房销售      1636\n",
      "无销售性质     1514\n",
      "期货        1473\n",
      "电话客服      1427\n",
      "含销售性质     1407\n",
      "贷款业务      1400\n",
      "基金销售      1392\n",
      "理财业务      1355\n",
      "高级销售      1298\n",
      "团队建设能力    1286\n",
      "区域销售      1283\n",
      "会销        1217\n",
      "对公业务      1149\n",
      "全职兼职均可    1117\n",
      "管理能力      1106\n",
      "保险理赔      1106\n",
      "银行销售      1064\n",
      "业务管理      1060\n",
      "贷款        1056\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('finance_skills.csv')\n",
    "\n",
    "# Define a dictionary to store the cleaned skills\n",
    "skills_dict = {}\n",
    "\n",
    "# Iterate through each row in the info column\n",
    "for row in df['info']:\n",
    "    # Extract the skills from the row and clean them\n",
    "    row_skills = re.findall(r'\\b\\w+\\b', row.lower())\n",
    "    row_skills = {s.strip() for s in row_skills if s.strip() and s not in ['TO C', 'TO B', 'TO G', '早九晚六', '五险一金', '应届生', '银行', '线下授课','旅游业', '农/林/牧/渔', '餐饮业','全国', '不出差','汽车','互联网行业','典当业','C端客户','建筑业','个人业务', '全职']}\n",
    "    \n",
    "    # Count the frequency of each skill and update the skills dictionary\n",
    "    for skill in row_skills:\n",
    "        skill_lower = skill.lower() # convert skill to lowercase\n",
    "        if skill_lower in skills_dict:\n",
    "            skills_dict[skill_lower] += 1\n",
    "        else:\n",
    "            skills_dict[skill_lower] = 1\n",
    "\n",
    "# Filter out low-frequency skills\n",
    "skills_dict = {k: v for k, v in skills_dict.items() if v >= 500}\n",
    "\n",
    "# Count the frequency of each skill in the dataframe\n",
    "skills_count = {k: sum(df['info'].str.lower().str.contains(r'\\b{}\\b'.format(re.escape(k)))) for k in skills_dict.keys()}\n",
    "\n",
    "# Convert the skills count dictionary to a pandas dataframe and sort by count\n",
    "skills_count_df = pd.DataFrame.from_dict(skills_count, orient='index', columns=['count'])\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df = skills_count_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Count the frequency of each skill in the dataframe and save to a csv file\n",
    "skills_count_df.index.name = 'skill'\n",
    "skills_count_df.to_csv('finance_skills_counts.csv')\n",
    "\n",
    "# Only show the top 50 skills with the highest count\n",
    "skills_count_top50 = skills_count_df.head(50)\n",
    "print(skills_count_top50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('finance_skills.csv')\n",
    "\n",
    "# Define a set of different skills\n",
    "skills_set = {'面销','电话销售','网络销售','金融销售','保险销售','渠道销售','互联网金融','证券从业资格证','电销','基金从业资格证','大客户销售','二手房销售','理财销售','店面销售','新房销售','电话客服','基金销售','区域销售','团队建设能力'}\n",
    "\n",
    "# Iterate through each row in the info column\n",
    "result_rows = []\n",
    "for i, row in df.iterrows():\n",
    "    row_skills = set(re.findall(r'\\b\\w+\\b', row['info'].lower())) # Extract the skills from the row and clean them\n",
    "    row_skills = {s.strip() for s in row_skills if s.strip() and s not in ['TO C', 'TO B', 'TO G', '早九晚六', '五险一金', '应届生', '银行', '线下授课','旅游业', '农/林/牧/渔', '餐饮业','全国', '不出差','汽车','互联网行业','典当业','C端客户','建筑业','个人业务', '全职']}\n",
    "    if len(row_skills & skills_set) >= 2: # Check if the intersection of the row skills and the skills set has at least 2 elements\n",
    "        result_rows.append(row)\n",
    "\n",
    "\n",
    "# Save the skills in a CSV file\n",
    "df_skills = pd.DataFrame(result_rows)\n",
    "df_skills.to_csv('fin_skills.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 edges by weight:\n",
      "('SpringCloud', 'SpringBoot') - weight: 1873.0\n",
      "('后端开发', 'Java') - weight: 1749.0\n",
      "('SpringBoot', 'Java') - weight: 1592.0\n",
      "('后端开发', 'SpringBoot') - weight: 1490.0\n",
      "('Java', 'MySQL') - weight: 1308.0\n",
      "('SpringCloud', 'Java') - weight: 1293.0\n",
      "('电路设计', 'PCB设计') - weight: 1269.0\n",
      "('后端开发', 'SpringCloud') - weight: 1254.0\n",
      "('C语言', 'C++') - weight: 1213.0\n",
      "('Java', 'Python') - weight: 1123.0\n",
      "('C++', 'Python') - weight: 878.0\n",
      "('PS', '视觉设计') - weight: 812.0\n",
      "('SpringBoot', 'MySQL') - weight: 788.0\n",
      "('电路设计', '嵌入式硬件开发') - weight: 777.0\n",
      "('后端开发', 'MySQL') - weight: 732.0\n",
      "('PCB设计', '嵌入式硬件开发') - weight: 700.0\n",
      "('Linux', 'C++') - weight: 677.0\n",
      "('SpringCloud', 'MySQL') - weight: 622.0\n",
      "('SQL', 'Python') - weight: 605.0\n",
      "('SQL', 'Java') - weight: 581.0\n",
      "('Java', 'C++') - weight: 512.0\n",
      "('SQL', 'MySQL') - weight: 393.0\n",
      "('后端开发', 'Python') - weight: 377.0\n",
      "('后端开发', 'C++') - weight: 363.0\n",
      "('C语言', 'Python') - weight: 327.0\n",
      "('Python', 'MySQL') - weight: 315.0\n",
      "('Linux', 'Python') - weight: 310.0\n",
      "('Linux', 'MySQL') - weight: 297.0\n",
      "('Linux', 'Java') - weight: 293.0\n",
      "('C语言', 'Java') - weight: 282.0\n"
     ]
    }
   ],
   "source": [
    "with open('it_skills.csv', 'r') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# Preprocess text data to extract lists of words\n",
    "words_list = [set(line.strip().replace('[', '').replace(']', '').replace(\"'\", '').split(', ')) for line in text]\n",
    "for i in range(len(words_list)):\n",
    "    words_list[i] = {re.sub(r'\"', '', word) for word in words_list[i]}\n",
    "\n",
    "# List of target words\n",
    "target_words = ['SQL', 'Javascript', 'PS', '后端开发', 'CAD', 'Linux', 'SolidWorks', 'C语言', 'C++', '视觉设计',\n",
    "                'PCB设计', '嵌入式硬件开发', 'MySQL', 'Vue', '电路设计', 'Python', 'SpringBoot', 'Web前端',\n",
    "                'SpringCloud', 'Java']\n",
    "\n",
    "# Filter out words not in the target word list\n",
    "words_list = [words.intersection(target_words) for words in words_list]\n",
    "\n",
    "# Construct a dictionary of word-to-index mappings\n",
    "word_to_index = {word: i for i, word in enumerate(set.union(*words_list)) if word in target_words}\n",
    "\n",
    "# Initialize the co-occurrence matrix\n",
    "co_occurrence_matrix = np.zeros((len(word_to_index), len(word_to_index)))\n",
    "\n",
    "# Calculate the co-occurrence matrix\n",
    "for words in words_list:\n",
    "# Combine all skill words in this row of data and add to the co-occurrence matrix\n",
    "    for skill1, skill2 in combinations(words, 2):\n",
    "        if skill1 in word_to_index and skill2 in word_to_index:\n",
    "            co_occurrence_matrix[word_to_index[skill1], word_to_index[skill2]] += 1\n",
    "            co_occurrence_matrix[word_to_index[skill2], word_to_index[skill1]] += 1  # 矩阵应该对称\n",
    "\n",
    "# Set the diagonal of the co-occurrence matrix to 0\n",
    "np.fill_diagonal(co_occurrence_matrix, 0)\n",
    "\n",
    "# Construct a co-occurrence network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add each word as a node and set node size\n",
    "for word in word_to_index.keys():\n",
    "    G.add_node(word, size=0)\n",
    "\n",
    "# Calculate the degree of each word\n",
    "for i, word in enumerate(word_to_index.keys()):\n",
    "    for j in range(i+1, len(word_to_index)):\n",
    "        degree = co_occurrence_matrix[i, j]\n",
    "        if degree > 0:\n",
    "            word_degree = sum(co_occurrence_matrix[i]) + sum(co_occurrence_matrix[j])\n",
    "            node_size = degree / word_degree\n",
    "            G.add_edge(word, list(word_to_index.keys())[j], weight=degree)\n",
    "            G.nodes[word]['size'] += node_size\n",
    "            G.nodes[list(word_to_index.keys())[j]]['size'] += node_size\n",
    "\n",
    "# Dictionary to map Chinese labels to English labels\n",
    "label_dict = {'SQL': 'sql', 'Javascript': 'JS', 'PS': 'PS', '后端开发': 'backend', 'CAD': 'cad', 'Linux': 'linux',\n",
    "'SolidWorks': 'SolidWorks', 'C语言': 'C', 'C++': 'C++', '视觉设计': 'visual_design', 'PCB设计': 'pcb_design',\n",
    "'嵌入式硬件开发': 'embedded_hardware', 'MySQL': 'MySQL', 'Vue': 'Vue', '电路设计': 'circuit_design',\n",
    "'Python': 'python', 'SpringBoot': 'Spring Boot', 'Web前端': 'web_frontend', 'SpringCloud': 'Spring Cloud',\n",
    "'Java': 'java'} \n",
    "\n",
    "# Replace the labels in the network with English labels\n",
    "for node in G.nodes:\n",
    "    if node in label_dict:\n",
    "        G.nodes[node]['label'] = label_dict[node]\n",
    "\n",
    "# Get top 30 strongest edges by weight\n",
    "sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:30]\n",
    "top_edges = [(u, v) for u, v, d in sorted_edges]\n",
    "\n",
    "print(\"Top 30 edges by weight:\")\n",
    "for edge in top_edges:\n",
    "    weight = G[edge[0]][edge[1]]['weight']\n",
    "    print(f\"{edge} - weight: {weight}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 edges by weight:\n",
      "('网络销售', '电话销售') - weight: 2835.0\n",
      "('面销', '电话销售') - weight: 2272.0\n",
      "('网络销售', '面销') - weight: 2055.0\n",
      "('金融销售', '保险销售') - weight: 1655.0\n",
      "('网络销售', '渠道销售') - weight: 1595.0\n",
      "('金融销售', '理财销售') - weight: 1526.0\n",
      "('渠道销售', '面销') - weight: 1492.0\n",
      "('二手房销售', '新房销售') - weight: 1401.0\n",
      "('基金从业资格证', '证券从业资格证') - weight: 1330.0\n",
      "('保险销售', '面销') - weight: 1313.0\n",
      "('网络销售', '店面销售') - weight: 1205.0\n",
      "('金融销售', '大客户销售') - weight: 1188.0\n",
      "('金融销售', '面销') - weight: 1175.0\n",
      "('金融销售', '电话销售') - weight: 1175.0\n",
      "('渠道销售', '电话销售') - weight: 1156.0\n",
      "('电销', '面销') - weight: 1148.0\n",
      "('电话销售', '二手房销售') - weight: 1055.0\n",
      "('保险销售', '电话销售') - weight: 1021.0\n",
      "('理财销售', '基金销售') - weight: 1015.0\n",
      "('保险销售', '大客户销售') - weight: 1011.0\n",
      "('金融销售', '基金销售') - weight: 984.0\n",
      "('电销', '网络销售') - weight: 980.0\n",
      "('店面销售', '面销') - weight: 963.0\n",
      "('网络销售', '二手房销售') - weight: 869.0\n",
      "('电话销售', '新房销售') - weight: 837.0\n",
      "('金融销售', '团队建设能力') - weight: 810.0\n",
      "('面销', '大客户销售') - weight: 772.0\n",
      "('店面销售', '二手房销售') - weight: 739.0\n",
      "('电话销售', '大客户销售') - weight: 690.0\n",
      "('金融销售', '网络销售') - weight: 689.0\n"
     ]
    }
   ],
   "source": [
    "with open('fin_skills.csv', 'r') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# Preprocess text data to extract lists of words\n",
    "words_list = [set(line.strip().replace('[', '').replace(']', '').replace(\"'\", '').split(', ')) for line in text]\n",
    "for i in range(len(words_list)):\n",
    "    words_list[i] = {re.sub(r'\"', '', word) for word in words_list[i]}\n",
    "\n",
    "# List of target words\n",
    "target_words = ['面销','电话销售','网络销售','金融销售','保险销售','渠道销售','互联网金融','证券从业资格证','电销','基金从业资格证','大客户销售','二手房销售','理财销售','店面销售','新房销售','电话客服','基金销售','区域销售','团队建设能力']\n",
    "\n",
    "# Filter out words not in the target word list\n",
    "words_list = [words.intersection(target_words) for words in words_list]\n",
    "\n",
    "# Construct a dictionary of word-to-index mappings\n",
    "word_to_index = {word: i for i, word in enumerate(set.union(*words_list)) if word in target_words}\n",
    "\n",
    "# Initialize the co-occurrence matrix\n",
    "co_occurrence_matrix = np.zeros((len(word_to_index), len(word_to_index)))\n",
    "\n",
    "# Calculate the co-occurrence matrix\n",
    "for words in words_list:\n",
    "# Combine all skill words in this row of data and add to the co-occurrence matrix\n",
    "    for skill1, skill2 in combinations(words, 2):\n",
    "        if skill1 in word_to_index and skill2 in word_to_index:\n",
    "            co_occurrence_matrix[word_to_index[skill1], word_to_index[skill2]] += 1\n",
    "            co_occurrence_matrix[word_to_index[skill2], word_to_index[skill1]] += 1  # 矩阵应该对称\n",
    "\n",
    "# Set the diagonal of the co-occurrence matrix to 0\n",
    "np.fill_diagonal(co_occurrence_matrix, 0)\n",
    "\n",
    "# Construct a co-occurrence network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add each word as a node and set node size\n",
    "for word in word_to_index.keys():\n",
    "    G.add_node(word, size=0)\n",
    "\n",
    "# Calculate the degree of each word\n",
    "for i, word in enumerate(word_to_index.keys()):\n",
    "    for j in range(i+1, len(word_to_index)):\n",
    "        degree = co_occurrence_matrix[i, j]\n",
    "        if degree > 0:\n",
    "            word_degree = sum(co_occurrence_matrix[i]) + sum(co_occurrence_matrix[j])\n",
    "            node_size = degree / word_degree\n",
    "            G.add_edge(word, list(word_to_index.keys())[j], weight=degree)\n",
    "            G.nodes[word]['size'] += node_size\n",
    "            G.nodes[list(word_to_index.keys())[j]]['size'] += node_size\n",
    "\n",
    "# Dictionary to map Chinese labels to English labels\n",
    "label_dict = {'面销':'Face-to-face sales','电话销售':  'Telemarketing','网络销售':  'Online sales','金融销售':  'Financial sales','保险销售':  'Insurance sales','渠道销售':  'Channel sales','互联网金融': 'Internet finance','证券从业资格证':   'Securities qualification','电销':    'Telesales','基金从业资格证':   'Fund qualification','大客户销售': 'Key account sales','二手房销售': 'Second-hand housing sales','理财销售':  'Wealth management sales','店面销售':  'Store sales','新房销售':  'New house sales','电话客服': 'Telephone customer service','基金销售': 'Fund sales','区域销售': 'Regional sales','团队建设能力':'Team building'}\n",
    "\n",
    "# Replace the labels in the network with English labels\n",
    "for node in G.nodes:\n",
    "    if node in label_dict:\n",
    "        G.nodes[node]['label'] = label_dict[node]\n",
    "node_sizes = [1500 * G.nodes[word]['size'] for word in word_to_index.keys()]\n",
    "edge_labels = {(u, v): str(d['weight']) for u, v, d in G.edges(data=True)}\n",
    "\n",
    "# Get top 30 strongest edges by weight\n",
    "sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:30]\n",
    "top_edges = [(u, v) for u, v, d in sorted_edges]\n",
    "\n",
    "print(\"Top 30 edges by weight:\")\n",
    "for edge in top_edges:\n",
    "    weight = G[edge[0]][edge[1]]['weight']\n",
    "    print(f\"{edge} - weight: {weight}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03d18b7a4e5c4815e050dde1ecb8f7d94ee12a4d9ca69a286dac009428b60cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
